
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>cil.optimisation.functions.TotalVariation &#8212; CIL 24.2.1.dev6+g69391bb8 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../../_static/styles/theme.css?digest=5bdc4d852cc7e18db152" rel="stylesheet" />
<link href="../../../../../_static/styles/pydata-sphinx-theme.css?digest=5bdc4d852cc7e18db152" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/sg_gallery.css?v=d2d258e8" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../../_static/scripts/fontawesome.js?digest=5bdc4d852cc7e18db152"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../../_static/scripts/bootstrap.js?digest=5bdc4d852cc7e18db152" />
<link rel="preload" as="script" href="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=5bdc4d852cc7e18db152" />

    <script src="../../../../../_static/documentation_options.js?v=66ff1c35"></script>
    <script src="../../../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../../_static/copybutton.js?v=f281be69"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/cil/optimisation/functions/TotalVariation';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1dev0';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = '/CIL/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '24.2.1.dev6+g69391bb8';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <link rel="index" title="Index" href="../../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../../search/" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="24.2.1.dev6+g69391bb8" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../../search/"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
     
  

<a class="navbar-brand logo" href="/">
  
  
  
  
  
    
    
      
    
    
    <img src="https://ccpi.ac.uk/wp-content/uploads/2022/11/CIL-logo-RGB.svg" class="logo__image only-light" alt="CIL - Home"/>
    <img src="https://ccpi.ac.uk/wp-content/uploads/2022/11/CIL-logo-RGB-reversed.svg" class="logo__image only-dark pst-js-only" alt="CIL - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../introduction/">
    Introduction
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../framework/">
    Framework
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../io/">
    Read/ write AcquisitionData and ImageData
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../optimisation/">
    Optimisation framework
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../processors/">
    Processors
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../recon/">
    Recon
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../utilities/">
    Utilities
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../plugins/">
    CIL Plugins
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../developer_guide/">
    Developers’ Guide
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../../../../demos/">
    Tutorials
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../introduction/">
    Introduction
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../framework/">
    Framework
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../io/">
    Read/ write AcquisitionData and ImageData
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../optimisation/">
    Optimisation framework
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../processors/">
    Processors
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../recon/">
    Recon
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../utilities/">
    Utilities
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../plugins/">
    CIL Plugins
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../developer_guide/">
    Developers’ Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../demos/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../../../../../search/"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        <div class="sidebar-primary-item">
<h3><a href="../../../../../">Table of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../introduction/">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../framework/">Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../io/">Read/ write AcquisitionData and ImageData</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../optimisation/">Optimisation framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../optimisation/#block-framework">Block Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../processors/">Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../recon/">Recon</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../utilities/">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../plugins/">CIL Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../developer_guide/">Developers’ Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../demos/">Tutorials</a></li>
</ul>
</div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../../" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../../" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">cil.optimisation.functions.TotalVariation</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for cil.optimisation.functions.TotalVariation</h1><div class="highlight"><pre>
<span></span><span class="c1">#  Copyright 2020 United Kingdom Research and Innovation</span>
<span class="c1">#  Copyright 2020 The University of Manchester</span>
<span class="c1">#</span>
<span class="c1">#  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1">#  you may not use this file except in compliance with the License.</span>
<span class="c1">#  You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#      http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1">#  Unless required by applicable law or agreed to in writing, software</span>
<span class="c1">#  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1">#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1">#  See the License for the specific language governing permissions and</span>
<span class="c1">#  limitations under the License.</span>
<span class="c1">#</span>
<span class="c1"># Authors:</span>
<span class="c1"># CIL Developers, listed at: https://github.com/TomographicImaging/CIL/blob/master/NOTICE.txt</span>
<span class="c1"># Claire Delplancke (University of Bath)</span>


<span class="kn">from</span> <span class="nn">cil.optimisation.functions</span> <span class="kn">import</span> <span class="n">Function</span><span class="p">,</span> <span class="n">IndicatorBox</span><span class="p">,</span> <span class="n">MixedL21Norm</span><span class="p">,</span> <span class="n">MixedL11Norm</span>
<span class="kn">from</span> <span class="nn">cil.optimisation.operators</span> <span class="kn">import</span> <span class="n">GradientOperator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Number</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">cil.utilities.errors</span> <span class="kn">import</span> <span class="n">InPlaceError</span>

<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="TotalVariation">
<a class="viewcode-back" href="../../../../../optimisation/#cil.optimisation.functions.TotalVariation">[docs]</a>
<span class="k">class</span> <span class="nc">TotalVariation</span><span class="p">(</span><span class="n">Function</span><span class="p">):</span>

<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot; Total variation Function</span>

<span class="sd">    .. math:: \mathrm{TV}(u) := \|\nabla u\|_{2,1} = \sum \|\nabla u\|_{2},\, (\mbox{isotropic})</span>

<span class="sd">    .. math:: \mathrm{TV}(u) := \|\nabla u\|_{1,1} = \sum \|\nabla u\|_{1}\, (\mbox{anisotropic})</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>

<span class="sd">    The :code:`TotalVariation` (TV) :code:`Function` acts as a composite function, i.e.,</span>
<span class="sd">    the composition of the :class:`.MixedL21Norm` function and the :class:`.GradientOperator` operator,</span>

<span class="sd">    .. math:: f(u) = \|u\|_{2,1}, \Rightarrow (f\circ\nabla)(u) = f(\nabla x) = \mathrm{TV}(u)</span>

<span class="sd">    In that case, the proximal operator of TV does not have an exact solution and we use an iterative</span>
<span class="sd">    algorithm to solve:</span>

<span class="sd">    .. math:: \mathrm{prox}_{\tau \mathrm{TV}}(b) := \underset{u}{\mathrm{argmin}} \frac{1}{2\tau}\|u - b\|^{2} + \mathrm{TV}(u)</span>

<span class="sd">    The algorithm used for the proximal operator of TV is the Fast Gradient Projection algorithm (or FISTA)</span>
<span class="sd">    applied to the _dual problem_ of the above problem, see :cite:`BeckTeboulle_b`, :cite:`BeckTeboulle_a`, :cite:`Zhu2010`.</span>

<span class="sd">    See also &quot;Multicontrast MRI Reconstruction with Structure-Guided Total Variation&quot;, Ehrhardt, Betcke, 2016.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    max_iteration : :obj:`int`, default = 5</span>
<span class="sd">        Maximum number of iterations for the FGP algorithm to solve to solve the dual problem</span>
<span class="sd">        of the Total Variation Denoising problem (ROF). If warm_start=False, this should be around 100,</span>
<span class="sd">        or larger, with a set tolerance.</span>
<span class="sd">    tolerance : :obj:`float`, default = None</span>
<span class="sd">        Stopping criterion for the FGP algorithm used to to solve the dual problem</span>
<span class="sd">        of the Total Variation Denoising problem (ROF). If the difference between iterates in the FGP algorithm is less than the tolerance</span>
<span class="sd">        the iterations end before the max_iteration number.</span>

<span class="sd">        .. math:: \|x^{k+1} - x^{k}\|_{2} &lt; \mathrm{tolerance}</span>

<span class="sd">    correlation : :obj:`str`, default = `Space`</span>
<span class="sd">        Correlation between `Space` and/or `SpaceChannels` for the :class:`.GradientOperator`.</span>
<span class="sd">    backend :  :obj:`str`, default = `c`</span>
<span class="sd">        Backend to compute the :class:`.GradientOperator`</span>
<span class="sd">    lower : :obj:`&#39;float`, default = None</span>
<span class="sd">        A constraint is enforced using the :class:`.IndicatorBox` function, e.g., :code:`IndicatorBox(lower, upper)`.</span>
<span class="sd">    upper : :obj:`&#39;float`, default = None</span>
<span class="sd">        A constraint is enforced using the :class:`.IndicatorBox` function, e.g., :code:`IndicatorBox(lower, upper)`.</span>
<span class="sd">    isotropic : :obj:`boolean`, default = True</span>
<span class="sd">        Use either isotropic or anisotropic definition of TV.</span>

<span class="sd">        .. math:: |x|_{2} = \sqrt{x_{1}^{2} + x_{2}^{2}},\, (\mbox{isotropic})</span>

<span class="sd">        .. math:: |x|_{1} = |x_{1}| + |x_{2}|\, (\mbox{anisotropic})</span>

<span class="sd">    split : :obj:`boolean`, default = False</span>
<span class="sd">        Splits the Gradient into spatial gradient and spectral or temporal gradient for multichannel data.</span>

<span class="sd">    strong_convexity_constant : :obj:`float`, default = 0</span>
<span class="sd">        A strongly convex term weighted by the :code:`strong_convexity_constant` (:math:`\gamma`) parameter is added to the Total variation.</span>
<span class="sd">        Now the :code:`TotalVariation` function is :math:`\gamma` - strongly convex and the proximal operator is</span>

<span class="sd">        .. math:: \underset{u}{\mathrm{argmin}} \frac{1}{2\tau}\|u - b\|^{2} + \mathrm{TV}(u) + \frac{\gamma}{2}\|u\|^{2} \Leftrightarrow</span>

<span class="sd">        .. math:: \underset{u}{\mathrm{argmin}} \frac{1}{2\frac{\tau}{1+\gamma\tau}}\|u - \frac{b}{1+\gamma\tau}\|^{2} + \mathrm{TV}(u)</span>

<span class="sd">    warm_start : :obj:`boolean`, default = True</span>
<span class="sd">        If set to true, the FGP algorithm used to solve the dual problem of the Total Variation Denoising problem (ROF) is initiated by the final value from the previous iteration and not at zero.</span>
<span class="sd">        This allows the max_iteration value to be reduced to 5-10 iterations.</span>


<span class="sd">    Note</span>
<span class="sd">    ----</span>

<span class="sd">    With warm_start set to the default, True, the TV function will keep in memory the range of the gradient of the image to be denoised, i.e. N times the dimensionality of the image. This increases the memory requirements.</span>
<span class="sd">    However, during the evaluation of `proximal` the memory requirements will be unchanged as the same amount of memory will need to be allocated and deallocated.</span>

<span class="sd">    Note</span>
<span class="sd">    ----</span>

<span class="sd">    In the case where the Total variation becomes a :math:`\gamma` - strongly convex function, i.e.,</span>

<span class="sd">    .. math:: \mathrm{TV}(u) + \frac{\gamma}{2}\|u\|^{2}</span>

<span class="sd">    :math:`\gamma` should be relatively small, so as the second term above will not act as an additional regulariser.</span>
<span class="sd">    For more information, see :cite:`Rasch2020`, :cite:`CP2011`.</span>




<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. math:: \underset{u}{\mathrm{argmin}} \frac{1}{2}\|u - b\|^{2} + \alpha\|\nabla u\|_{2,1}</span>

<span class="sd">    &gt;&gt;&gt; alpha = 2.0</span>
<span class="sd">    &gt;&gt;&gt; TV = TotalVariation()</span>
<span class="sd">    &gt;&gt;&gt; sol = TV.proximal(b, tau = alpha)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. math:: \underset{u}{\mathrm{argmin}} \frac{1}{2}\|u - b\|^{2} + \alpha\|\nabla u\|_{1,1} + \mathbb{I}_{C}(u)</span>

<span class="sd">    where :math:`C = \{1.0\leq u\leq 2.0\}`.</span>

<span class="sd">    &gt;&gt;&gt; alpha = 2.0</span>
<span class="sd">    &gt;&gt;&gt; TV = TotalVariation(isotropic=False, lower=1.0, upper=2.0)</span>
<span class="sd">    &gt;&gt;&gt; sol = TV.proximal(b, tau = alpha)</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. math:: \underset{u}{\mathrm{argmin}} \frac{1}{2}\|u - b\|^{2} + (\alpha\|\nabla u\|_{2,1} + \frac{\gamma}{2}\|u\|^{2})</span>

<span class="sd">    &gt;&gt;&gt; alpha = 2.0</span>
<span class="sd">    &gt;&gt;&gt; gamma = 1e-3</span>
<span class="sd">    &gt;&gt;&gt; TV = alpha * TotalVariation(isotropic=False, strong_convexity_constant=gamma)</span>
<span class="sd">    &gt;&gt;&gt; sol = TV.proximal(b, tau = 1.0)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">max_iteration</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">tolerance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">correlation</span><span class="o">=</span><span class="s2">&quot;Space&quot;</span><span class="p">,</span>
                 <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">,</span>
                 <span class="n">lower</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">upper</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">isotropic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">split</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">strong_convexity_constant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">warm_start</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">TotalVariation</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Regularising parameter = alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularisation_parameter</span> <span class="o">=</span> <span class="mf">1.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span> <span class="o">=</span> <span class="n">max_iteration</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span> <span class="o">=</span> <span class="n">tolerance</span>

        <span class="c1"># Total variation correlation (isotropic=Default)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">isotropic</span> <span class="o">=</span> <span class="n">isotropic</span>

        <span class="c1"># correlation space or spacechannels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">correlation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span>

        <span class="c1"># Define orthogonal projection onto the convex set C</span>
        <span class="k">if</span> <span class="n">lower</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lower</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">if</span> <span class="n">upper</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">=</span> <span class="n">lower</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">=</span> <span class="n">upper</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_C</span> <span class="o">=</span> <span class="n">IndicatorBox</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span><span class="o">.</span><span class="n">proximal</span>

        <span class="c1"># Setup GradientOperator as None. This is to avoid domain argument in the __init__</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gradient</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_domain</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># splitting Gradient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">split</span>

        <span class="c1"># For the warm_start functionality</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span> <span class="o">=</span> <span class="n">warm_start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_p2</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Strong convexity for TV</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strong_convexity_constant</span> <span class="o">=</span> <span class="n">strong_convexity_constant</span>

        <span class="c1"># Define Total variation norm</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">isotropic</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">MixedL21Norm</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">MixedL11Norm</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_p2</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;The initial value for the dual in the proximal calculation - allocated to zero in the case of warm_start=False</span>
<span class="sd">          or initialised as the last iterate seen in the proximal calculation in the case warm_start=True .&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_p2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_operator</span><span class="o">.</span><span class="n">range_geometry</span><span class="p">()</span><span class="o">.</span><span class="n">allocate</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_p2</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">regularisation_parameter</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regularisation_parameter</span>

    <span class="nd">@regularisation_parameter</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">regularisation_parameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Number</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;regularisation_parameter: expected a number, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_regularisation_parameter</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot; Returns the value of the TotalVariation function at :code:`x` .&quot;&quot;&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_domain</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">geometry</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_domain</span> <span class="o">=</span> <span class="n">x</span>

        <span class="c1"># Compute Lipschitz constant provided that domain is not None.</span>
        <span class="c1"># Lipschitz constant dependes on the GradientOperator, which is configured only if domain is not None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_L</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">calculate_Lipschitz</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strong_convexity_constant</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">strongly_convex_term</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">strong_convexity_constant</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">squared_norm</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">strongly_convex_term</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularisation_parameter</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_operator</span><span class="o">.</span><span class="n">direct</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="n">strongly_convex_term</span>

<div class="viewcode-block" id="TotalVariation.proximal">
<a class="viewcode-back" href="../../../../../optimisation/#cil.optimisation.functions.TotalVariation.proximal">[docs]</a>
    <span class="k">def</span> <span class="nf">proximal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot; Returns the proximal operator of the TotalVariation function at :code:`x` .&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">==</span><span class="nb">id</span><span class="p">(</span><span class="n">out</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">InPlaceError</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;TotalVariation.proximal cannot be used in place&quot;</span><span class="p">)</span>


        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strong_convexity_constant</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>

            <span class="n">strongly_convex_factor</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">tau</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">strong_convexity_constant</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">/=</span> <span class="n">strongly_convex_factor</span>
            <span class="n">tau</span> <span class="o">/=</span> <span class="n">strongly_convex_factor</span>
        <span class="n">solution</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fista_on_dual_rof</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strong_convexity_constant</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">*=</span> <span class="n">strongly_convex_factor</span>
            <span class="n">tau</span> <span class="o">*=</span> <span class="n">strongly_convex_factor</span>

        <span class="k">return</span> <span class="n">solution</span></div>


    <span class="k">def</span> <span class="nf">_fista_on_dual_rof</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot; Runs the Fast Gradient Projection (FGP) algorithm to solve the dual problem</span>
<span class="sd">        of the Total Variation Denoising problem (ROF).</span>

<span class="sd">        .. math: \max_{\|y\|_{\infty}&lt;=1.} \frac{1}{2}\|\nabla^{*} y + x \|^{2} - \frac{1}{2}\|x\|^{2}</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_domain</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">geometry</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_domain</span> <span class="o">=</span> <span class="n">x</span>

        <span class="c1"># Compute Lipschitz constant provided that domain is not None.</span>
        <span class="c1"># Lipschitz constant depends on the GradientOperator, which is configured only if domain is not None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_L</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">calculate_Lipschitz</span><span class="p">()</span>

        <span class="c1"># initialise</span>
        <span class="n">t</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="c1"># dual variable - its content is overwritten during iterations</span>
        <span class="n">p1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_operator</span><span class="o">.</span><span class="n">range_geometry</span><span class="p">()</span><span class="o">.</span><span class="n">allocate</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">p2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_p2</span><span class="p">()</span>
        <span class="n">tmp_q</span> <span class="o">=</span> <span class="n">p2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># multiply tau by -1 * regularisation_parameter here so it&#39;s not recomputed every iteration</span>
        <span class="c1"># when tau is an array this is done inplace so reverted at the end</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">Number</span><span class="p">):</span>
            <span class="n">tau_reg_neg</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">regularisation_parameter</span> <span class="o">*</span> <span class="n">tau</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tau_reg_neg</span> <span class="o">=</span> <span class="n">tau</span>
            <span class="n">tau</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">regularisation_parameter</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">tau_reg_neg</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_operator</span><span class="o">.</span><span class="n">domain_geometry</span><span class="p">()</span><span class="o">.</span><span class="n">allocate</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">):</span>

            <span class="n">t0</span> <span class="o">=</span> <span class="n">t</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gradient_operator</span><span class="o">.</span><span class="n">adjoint</span><span class="p">(</span><span class="n">tmp_q</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">sapyb</span><span class="p">(</span><span class="n">tau_reg_neg</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">projection_C</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">gradient_operator</span><span class="o">.</span><span class="n">direct</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">p1</span><span class="p">)</span>

            <span class="n">multip</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">)</span><span class="o">/</span><span class="n">tau_reg_neg</span>

            <span class="n">tmp_q</span><span class="o">.</span><span class="n">sapyb</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">p1</span><span class="p">,</span> <span class="n">multip</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">tmp_q</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">k</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">p1</span> <span class="o">*=</span> <span class="n">multip</span>
                <span class="n">error</span> <span class="o">=</span> <span class="n">p1</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
                <span class="n">error</span> <span class="o">/=</span> <span class="n">tmp_q</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">error</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">:</span>
                    <span class="k">break</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">proximal_conjugate</span><span class="p">(</span><span class="n">tmp_q</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">p1</span><span class="p">)</span>

            <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">t0</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">p1</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">p2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">tmp_q</span><span class="p">)</span>
            <span class="n">tmp_q</span> <span class="o">*=</span> <span class="p">(</span><span class="n">t0</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">t</span>
            <span class="n">tmp_q</span> <span class="o">+=</span> <span class="n">p1</span>

            <span class="c1"># switch p1 and p2 references</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">p1</span>
            <span class="n">p1</span> <span class="o">=</span> <span class="n">p2</span>
            <span class="n">p2</span> <span class="o">=</span> <span class="n">tmp</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warm_start</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_p2</span> <span class="o">=</span> <span class="n">p2</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Stop at </span><span class="si">%d</span><span class="s2"> iterations with tolerance </span><span class="si">%r</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Stop at </span><span class="si">%d</span><span class="s2"> iterations.&quot;</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>

        <span class="c1"># return tau to its original state if it was modified</span>
        <span class="k">if</span> <span class="nb">id</span><span class="p">(</span><span class="n">tau_reg_neg</span><span class="p">)</span> <span class="o">==</span> <span class="nb">id</span><span class="p">(</span><span class="n">tau</span><span class="p">):</span>
            <span class="n">tau_reg_neg</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">regularisation_parameter</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">tau</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>

<div class="viewcode-block" id="TotalVariation.convex_conjugate">
<a class="viewcode-back" href="../../../../../optimisation/#cil.optimisation.functions.TotalVariation.convex_conjugate">[docs]</a>
    <span class="k">def</span> <span class="nf">convex_conjugate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot; Returns the value of convex conjugate of the TotalVariation function at :code:`x` .&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">0.0</span></div>


<div class="viewcode-block" id="TotalVariation.calculate_Lipschitz">
<a class="viewcode-back" href="../../../../../optimisation/#cil.optimisation.functions.TotalVariation.calculate_Lipschitz">[docs]</a>
    <span class="k">def</span> <span class="nf">calculate_Lipschitz</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot; Default value for the Lipschitz constant.&quot;&quot;&quot;</span>

        <span class="c1"># Compute the Lipschitz parameter from the operator if possible</span>
        <span class="c1"># Leave it initialised to None otherwise</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_L</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_operator</span><span class="o">.</span><span class="n">norm</span><span class="p">())</span><span class="o">**</span><span class="mi">2</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">gradient_operator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot; GradientOperator is created if it is not instantiated yet. The domain of the `_gradient`,</span>
<span class="sd">        is created in the `__call__` and `proximal` methods.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_domain</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_gradient</span> <span class="o">=</span> <span class="n">GradientOperator</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_domain</span><span class="p">,</span> <span class="n">correlation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">correlation</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot; The domain of the TotalVariation is </span><span class="si">{}</span><span class="s2">. Please use the __call__ or proximal methods first before calling gradient.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_domain</span><span class="p">))</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient</span>

    <span class="k">def</span> <span class="fm">__rmul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scalar</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scalar</span><span class="p">,</span> <span class="n">Number</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;scalar: Expected a number, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">scalar</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularisation_parameter</span> <span class="o">*=</span> <span class="n">scalar</span>
        <span class="k">return</span> <span class="bp">self</span></div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../../_static/scripts/bootstrap.js?digest=5bdc4d852cc7e18db152"></script>
<script defer src="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=5bdc4d852cc7e18db152"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2017-2024.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>