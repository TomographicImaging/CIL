{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mrcfile\n",
    "from ccpi.io import *\n",
    "from ccpi.framework import AcquisitionData, AcquisitionGeometry, ImageGeometry, ImageData\n",
    "from ccpi.optimisation.algorithms import CGLS, PDHG, FISTA\n",
    "from ccpi.optimisation.operators import BlockOperator, Gradient\n",
    "from ccpi.optimisation.functions import L2NormSquared, ZeroFunction, MixedL21Norm, L1Norm\n",
    "\n",
    "from ccpi.astra.operators import AstraProjectorSimple , AstraProjector3DSimple\n",
    "from ccpi.astra.processors import FBP\n",
    "\n",
    "from ccpi.utilities.jupyter import islicer, link_islicer\n",
    "from ccpi.utilities.display import plotter2D\n",
    "\n",
    "# All external imports\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from ccpi.framework import AcquisitionData, AcquisitionGeometry, ImageData, ImageGeometry\n",
    "import datetime\n",
    "from PIL import Image\n",
    "\n",
    "class TIFFWriter(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 **kwargs):\n",
    "        \n",
    "        self.data_container = kwargs.get('data_container', None)\n",
    "        self.file_name = kwargs.get('file_name', None)\n",
    "        \n",
    "        if ((self.data_container is not None) and (self.file_name is not None)):\n",
    "            self.set_up(data_container = self.data_container,\n",
    "                        file_name = self.file_name)\n",
    "        \n",
    "    def set_up(self,\n",
    "               data_container = None,\n",
    "               file_name = None):\n",
    "        \n",
    "        self.data_container = data_container\n",
    "        self.file_name = file_name\n",
    "        \n",
    "        if not ((isinstance(self.data_container, ImageData)) or \n",
    "                (isinstance(self.data_container, AcquisitionData))):\n",
    "            raise Exception('Writer supports only following data types:\\n' +\n",
    "                            ' - ImageData\\n - AcquisitionData')\n",
    "\n",
    "    def write_file(self):\n",
    "        '''alias of write'''\n",
    "        return self.write()\n",
    "    \n",
    "    def write(self):\n",
    "        ndim = len(self.data_container.shape)\n",
    "        if ndim == 2:\n",
    "            # save single slice\n",
    "            with open(self.file_name, 'wb') as f:\n",
    "                Image.fromarray(self.data_container.as_array()).save(f, 'tiff')\n",
    "        elif ndim == 3:\n",
    "            for sliceno in range(self.data_container.shape[0]):\n",
    "                # save single slice\n",
    "                # pattern = self.file_name.split('.')\n",
    "                dimension = self.data_container.dimension_labels[0]\n",
    "                fname = \"{}_idx_{}.tiff\".format(self.file_name.strip(\".tiff\"), sliceno)\n",
    "                with open(fname, 'wb') as f:\n",
    "                    Image.fromarray(self.data_container.as_array()[sliceno]).save(f, 'tiff')\n",
    "        elif ndim == 4:\n",
    "            for sliceno1 in range(self.data_container.shape[0]):\n",
    "                # save single slice\n",
    "                # pattern = self.file_name.split('.')\n",
    "                dimension = [ self.data_container.dimension_labels[0] ]\n",
    "                for sliceno2 in range(self.data_container.shape[1]):\n",
    "                    idx = self.data_container.shape[0] * sliceno2 + sliceno1 \n",
    "                    fname = \"{}_{}_{}_idx_{}.tiff\".format(self.file_name.strip(\".tiff\"), \n",
    "                        self.data_container.shape[0], self.data_container.shape[1], idx)\n",
    "                    with open(fname, 'wb') as f:\n",
    "                        Image.fromarray(self.data_container.as_array()[sliceno1][sliceno2]).save(f, 'tiff')\n",
    "        else:\n",
    "            raise ValueError('Cannot handle more than 4 dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1.0999998, 1.0999995, 1.1)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<ccpi.framework.framework.AcquisitionData at 0x7f32bb087d30>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# remove two angles for the aligned file\n",
    "# angles should be in radians\n",
    "angles = np.loadtxt('tomo_01.tlt') / 180. * np.pi\n",
    "\n",
    "centre_slice = 2150\n",
    "\n",
    "with mrcfile.open('tomo_01.ali') as mrc:\n",
    "    #ndarray = mrc.data.copy()\n",
    "    shape = mrc.data.shape\n",
    "    # reconstruct on a smaller virtual panel\n",
    "    vpanel_v_size = shape[2]#,3\n",
    "    vox_size = mrc.voxel_size\n",
    "    print (vox_size)\n",
    "    # print (type(vox_size))\n",
    "    vpanel_v_size = vpanel_v_size if vpanel_v_size != 1 else shape[2]\n",
    "    \n",
    "    ag = AcquisitionGeometry('parallel', '3D', \n",
    "                             pixel_num_h = shape[2],\n",
    "                             pixel_num_v = shape[1],# vpanel_v_size, \n",
    "                             pixel_size_h = np.floor(np.float32(vox_size['y'])* 100 + 0.5 ) / 100.,\n",
    "                             pixel_size_v = np.floor(np.float32(vox_size['z'])* 100 + 0.5 ) / 100.,\n",
    "                             angles = angles[:-2],\n",
    "                             angle_unit='radian',\n",
    "                             dimension_labels=['angle', 'vertical', 'horizontal' ],\n",
    "                            )\n",
    "    tomo = ag.allocate(None)\n",
    "    if vpanel_v_size == shape[2]:\n",
    "        tomo.fill(mrc.data)\n",
    "    else:\n",
    "        band = int(vpanel_v_size/2)\n",
    "        tomo.fill(mrc.data[:,:,centre_slice - band:centre_slice+band+1])\n",
    "    # print (mrc.data.shape)\n",
    "    \n",
    "# \"normalise\" in min/max range. Could be better to do in 1-99 percentile.\n",
    "tomo.subtract(tomo.min(), out=tomo)\n",
    "tomo.divide(tomo.max()-tomo.min(), out=tomo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.0 1.0\n877\n795\n715\n638\n565\n495\n430\n369\n312\n259\n211\n168\n129\n95\n66\n42\n23\n10\n2\n0\n2\n10\n23\n41\n64\n92\n125\n163\n206\n253\n305\n362\n423\n488\n557\n629\n706\n785\n873\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=19, continuous_update=False, description='angle', max=38), FloatRangeSliâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f288ed2eb35243599137315a1ecefb39"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "IntSlider(value=19, continuous_update=False, description='angle', max=38)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7d7ad4089f042d7870af0f7f08819b3"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "if True:\n",
    "    # remove borders and use contrast\n",
    "    border_value = 1\n",
    "    print(tomo.min(), tomo.max())\n",
    "    for i,angle in enumerate(angles[1:-1]):\n",
    "        dslice = tomo.subset(angle=i).as_array()\n",
    "        \n",
    "        # do it along horizontal axis\n",
    "        x = int((shape[2]) / 2 * (1 - np.cos(angle)))\n",
    "        print (x)\n",
    "        if x != 0:\n",
    "            dslice[:,0:x] = 1\n",
    "            zero = np.ones_like(dslice) * border_value\n",
    "            zero[:,x:-x] = dslice[:,x:-x]\n",
    "        else:\n",
    "            zero = dslice\n",
    "        # dslice[:,:-x] = 0\n",
    "        tomo.fill(zero, angle=i)\n",
    "islicer (tomo, direction='angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the data to match what Astra projector expects\n",
    "# take -log , remove zeros by adding epsilon\n",
    "epsilon = 1e-7\n",
    "tomost = -1 * (tomo.subset(dimensions=['vertical','angle','horizontal'])+epsilon).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# islicer(tomost, direction='angle', cmap='viridis', size=10, minmax=(0,2))\n",
    "# plotter2D(tomo.subset(angle=10), stretch_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of channels: 1\nvoxel_num : x667,y100,z642\nvoxel_size : x5.5,y5.5,z5.5\ncenter : x0,y0,z0\n\n"
    }
   ],
   "source": [
    "# Create Image Geometry\n",
    "# scale the output to test\n",
    "\n",
    "scale = 5\n",
    "vox_size = ag.pixel_size_h * scale\n",
    "\n",
    "ig = ImageGeometry(voxel_num_x= int(ag.pixel_num_h/scale - (500./scale) ),\n",
    "                   voxel_num_y= int(500 / scale), \n",
    "                   voxel_num_z= int(ag.pixel_num_v/scale - (500./scale)),\n",
    "                   voxel_size_x=vox_size,\n",
    "                   voxel_size_y=vox_size,\n",
    "                   voxel_size_z=vox_size)\n",
    "\n",
    "\n",
    "print (ig)\n",
    "A = AstraProjector3DSimple(ig, ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_init = ig.allocate(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Initialised GradientOperator with C backend running with  16  threads\n"
    }
   ],
   "source": [
    "from ccpi.optimisation.operators import Identity\n",
    "from ccpi.framework import BlockDataContainer\n",
    "# L = Identity(ig)\n",
    "L = Gradient(ig)\n",
    "if True:\n",
    "    if scale == 5:\n",
    "        alpha = 111.\n",
    "    elif scale == 1:\n",
    "        alpha = 49.96\n",
    "    elif scale == 2:\n",
    "        alpha = 72\n",
    "else:\n",
    "    # alpha prop to ratio of norm of A and norm of L\n",
    "    print (\"calculating norm of A\")\n",
    "    normA = A.norm()\n",
    "    print (\"calculating norm of Gradient\")\n",
    "    normL = L.norm()\n",
    "    ratio = normA/normL\n",
    "\n",
    "    # gamma selects the weighing between the regularisation and the fitting term:\n",
    "    # 1 means equal weight\n",
    "    # \n",
    "    gamma = 1 \n",
    "    alpha = gamma * ratio\n",
    "    print (alpha, normA, normL, normL/normA, normA/normL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LCGLS(CGLS):\n",
    "\n",
    "    def set_up(self, x_init, operator, data, tolerance=1e-6):\n",
    "        '''initialisation of the algorithm\n",
    "\n",
    "        :param operator: Linear operator for the inverse problem\n",
    "        :param x_init: Initial guess ( Default x_init = 0)\n",
    "        :param data: Acquired data to reconstruct       \n",
    "        :param tolerance: Tolerance/ Stopping Criterion to end CGLS algorithm\n",
    "        '''\n",
    "        print(\"{} setting up\".format(self.__class__.__name__, ))\n",
    "        \n",
    "        self.x = x_init * 0.\n",
    "        self.operator = operator\n",
    "        self.tolerance = tolerance\n",
    "\n",
    "        self.r = data - self.operator.direct(self.x)\n",
    "        \n",
    "        # self.s = self.operator.adjoint(self.r)\n",
    "        # self.p = self.s.copy()\n",
    "        self.p = self.operator.adjoint(self.r)\n",
    "        self.s = self.p.copy()\n",
    "\n",
    "        self.q = self.operator.range_geometry().allocate()\n",
    "        self.norms = self.p.norm()\n",
    "        self.norms0 = self.norms\n",
    "        self.gamma = self.norms**2\n",
    "        self.normx = self.x.norm()\n",
    "        # self.xmax = self.normx   \n",
    "        \n",
    "        self.loss.append(self.r.squared_norm())\n",
    "        self.configured = True\n",
    "        print(\"{} configured\".format(self.__class__.__name__, ))\n",
    "     \n",
    "    def update(self):\n",
    "        '''single iteration'''\n",
    "        \n",
    "        self.operator.direct(self.p, out=self.q)\n",
    "        delta = self.q.squared_norm()\n",
    "        # print (\"delta {} self.q.shape {}\".format(delta, self.q.shape))\n",
    "        alpha = self.gamma/delta\n",
    "        # update residuals\n",
    "        self.r.axpby(1, -alpha, self.q, out=self.r)\n",
    "        \n",
    "        # update solution\n",
    "        self.x.axpby(1, alpha, self.p, out=self.x)\n",
    "        #self.x += alpha * self.p\n",
    "        #self.r -= alpha * self.q\n",
    "        \n",
    "        self.operator.adjoint(self.r, self.s)\n",
    "        \n",
    "        self.norms = self.s.norm()\n",
    "        # print (\"self.norms {}\".format(self.norms))\n",
    "        self.gamma1 = self.gamma\n",
    "        self.gamma = self.norms**2\n",
    "        self.beta = self.gamma/self.gamma1\n",
    "        #self.p = self.s + self.beta * self.p   \n",
    "        self.p.axpby(self.beta, 1, self.s, out=self.p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_block = BlockOperator( A, alpha * L)\n",
    "\n",
    "zero_data = L.range_geometry().allocate(0)\n",
    "\n",
    "data_block = BlockDataContainer(tomost, zero_data)\n",
    "  \n",
    "cgls_regularised = LCGLS(operator=operator_block, data=data_block, \n",
    "                        update_objective_interval = 10)\n",
    "cgls_regularised.max_iteration = 10000\n",
    "\n",
    "cgls_regularised.run(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LRCGLS setting up\nInitialised GradientOperator with C backend running with  16  threads\nLRCGLS configured\n     Iter   Max Iter     Time/Iter            Objective\n                               [s]                     \n        0        100         0.000          4.33306e+08\n       10        100        15.082          4.09039e+08\n       20        100        11.270          3.62040e+08\n       30        100        13.996          3.48920e+08\n       40        100        11.957          3.41276e+08\n       50        100        14.702          3.35920e+08\n       50        100        14.702          3.35920e+08\nStop criterion has been reached.\n"
    }
   ],
   "source": [
    "from ccpi.optimisation.algorithms import CGLS\n",
    "import numpy\n",
    "\n",
    "import multiprocessing as mp\n",
    "from contextlib import closing\n",
    "\n",
    "import time\n",
    "\n",
    "def save_callback(iteration, obj, solution):\n",
    "    writer = NEXUSDataWriter()\n",
    "    writer.set_up(data_container=solution, \n",
    "                  file_name=\"./scale_2_gamma1_it_{}.nxs\".format(iteration)\n",
    "    )\n",
    "    writer.write_file()\n",
    "\n",
    "class LRCGLS(CGLS):\n",
    "    '''Regularised CGLS\n",
    "\n",
    "    Tikhonov regularisation\n",
    "    '''\n",
    "    def __init__(self, x_init=None, operator=None, data=None, tolerance=1e-6, **kwargs):\n",
    "        '''initialisation of the algorithm\n",
    "\n",
    "        :param operator : Linear operator for the inverse problem\n",
    "        :param x_init : Initial guess ( Default x_init = 0)\n",
    "        :param data : Acquired data to reconstruct       \n",
    "        :param tolerance: Tolerance/ Stopping Criterion to end CGLS algorithm\n",
    "        '''\n",
    "        super(CGLS, self).__init__(**kwargs)\n",
    "        \n",
    "        alpha = kwargs.get('alpha', None)\n",
    "        preallocate = kwargs.get('preallocate', False)\n",
    "\n",
    "        if alpha is None:\n",
    "            raise ValueError('Please specify alpha')\n",
    "\n",
    "        if x_init is None and operator is not None:\n",
    "            x_init = operator.domain_geometry().allocate(0)\n",
    "        if x_init is not None and operator is not None and data is not None:\n",
    "            if preallocate:\n",
    "                self.set_up(x_init=x_init, operator=operator, data=data, tolerance=tolerance, alpha=alpha)\n",
    "            else:\n",
    "                self.set_up_nopreallocate(x_init, operator, data, tolerance, alpha)\n",
    "                self.update_back = self.update\n",
    "                self.update = self.update_nopreallocate\n",
    "\n",
    "    def set_up_nopreallocate(self, x_init, operator, data, tolerance=1e-6, alpha=1e-2):\n",
    "        '''initialise the algorithm with minimal memory footprint'''\n",
    "        print(\"{} setting up\".format(self.__class__.__name__, ))\n",
    "        \n",
    "        self.x = x_init * 0.\n",
    "        data = BlockDataContainer(data, 0)\n",
    "        gradient = Gradient(operator.domain_geometry(), backend='c')\n",
    "        gradient.scalar = alpha\n",
    "        self.operator = BlockOperator(operator, gradient)\n",
    "        self.tolerance = tolerance\n",
    "\n",
    "        # self.r = data - self.operator.direct(self.x)\n",
    "        self.r = BlockDataContainer(- operator.direct(self.x), -gradient.scalar * gradient.direct(self.x)) + data\n",
    "        #self.s = self.operator.adjoint(self.r)\n",
    "        self.s = gradient.adjoint(self.r.get_item(1))\n",
    "        self.s.multiply(gradient.scalar, out=self.s)\n",
    "        self.s.add(operator.adjoint(self.r.get_item(0)), out=self.s)\n",
    "\n",
    "        self.p = self.s.copy()\n",
    "        # don't need to preallocate as we reallocate at each iteration\n",
    "        # self.q = self.operator.range_geometry().allocate()\n",
    "        self.norms0 = self.s.norm()\n",
    "        \n",
    "        self.norms = self.s.norm()\n",
    "\n",
    "        self.gamma = self.norms0**2\n",
    "        self.normx = self.x.norm()\n",
    "        self.xmax = self.normx   \n",
    "        \n",
    "        self.loss.append(self.r.squared_norm())\n",
    "        self.configured = True\n",
    "        print(\"{} configured\".format(self.__class__.__name__, ))\n",
    "    \n",
    "    def update_nopreallocate(self):\n",
    "        '''single iteration'''\n",
    "        gradient = self.operator.get_item(0,1)\n",
    "\n",
    "        term0 = self.operator.get_item(0,0).direct(self.p)\n",
    "        delta0 = term0.squared_norm()\n",
    "        # self.operator.get_item(0,0).direct(self.p, out=self.q.get_item(0))\n",
    "        # delta0 = self.q.get_item(0).squared_norm()\n",
    "        delta1, term1 = self.operator.get_item(0,1).direct_L21norm(self.p)\n",
    "        #term1.multiply(gradient.scalar, out=self.q.get_item(1))\n",
    "        term1.multiply(gradient.scalar, out=term1)\n",
    "        q = BlockDataContainer(term0, term1)\n",
    "\n",
    "        delta = delta0 + delta1\n",
    "        # print (\"delta\", delta, \"delta0\", delta0, \"delta1\", delta1)\n",
    "        # delta = self.q.squared_norm()\n",
    "\n",
    "        alpha = self.gamma/delta\n",
    "        # print (\"alpha\", alpha)                        \n",
    "        # self.x += alpha * self.p\n",
    "        # self.r -= alpha * self.q\n",
    "        \n",
    "        self.x.axpby(1, alpha, self.p, out=self.x)\n",
    "        #self.x += alpha * self.p\n",
    "        self.r.axpby(1, -alpha, q, out=self.r)\n",
    "        del q, term0, term1\n",
    "        #self.r -= alpha * self.q\n",
    "\n",
    "        # adjoint of block operator is sum of adjoints\n",
    "        # sumsq, self.s = self.operator.adjoint(self.r)\n",
    "        term0 = self.operator.get_item(0,0).adjoint(self.r.get_item(0))\n",
    "        delta0 = term0.norm()\n",
    "        delta1, term1 = gradient.adjoint_L21norm(self.r.get_item(1))\n",
    "        self.norms = delta0 + numpy.sqrt(delta1)\n",
    "        # self.norms = self.s.norm()\n",
    "\n",
    "        #term0.add(term1, out=self.s)\n",
    "        term0.axpby(1,gradient.scalar, term1, out=self.s)\n",
    "        # print (\"self.norms {}\".format(self.norms))\n",
    "        \n",
    "        self.gamma1 = self.gamma\n",
    "        self.gamma = self.norms**2\n",
    "        self.beta = self.gamma/self.gamma1\n",
    "        self.p.axpby(self.beta, 1., self.s , out=self.p)\n",
    "        \n",
    "        self.normx = self.x.norm()\n",
    "        self.xmax = numpy.maximum(self.xmax, self.normx)\n",
    "\n",
    "\n",
    "    def set_up(self, x_init, operator, data, tolerance=1e-6, alpha=1e-2):\n",
    "        '''initialisation of the algorithm\n",
    "\n",
    "        :param operator: Linear operator for the inverse problem\n",
    "        :param x_init: Initial guess ( Default x_init = 0)\n",
    "        :param data: Acquired data to reconstruct       \n",
    "        :param tolerance: Tolerance/ Stopping Criterion to end CGLS algorithm\n",
    "        :param alpha: regularisation parameter\n",
    "        '''\n",
    "        print(\"{} setting up\".format(self.__class__.__name__, ))\n",
    "        \n",
    "        self.x = x_init * 0.\n",
    "        #data = BlockDataContainer(data, operator.domain_geometry().allocate(0))\n",
    "        data = BlockDataContainer(data, 0)\n",
    "        gradient = Gradient(operator.domain_geometry(), backend='c')\n",
    "        gradient.scalar = alpha\n",
    "        self.operator = BlockOperator(operator, gradient)\n",
    "        self.tolerance = tolerance\n",
    "        self.q = self.operator.range_geometry().allocate()\n",
    "\n",
    "        # self.r = data - self.operator.direct(self.x)\n",
    "        # self.r = data - BlockDataContainer(operator.direct(self.x), gradient.scalar * gradient.direct(self.x))\n",
    "        self.r = BlockDataContainer(- operator.direct(self.x), - gradient.scalar * gradient.direct(self.x)) + data\n",
    "        #self.s = self.operator.adjoint(self.r)\n",
    "        self.p = gradient.adjoint(self.r.get_item(1))\n",
    "        self.p.multiply(gradient.scalar, out=self.p)\n",
    "        self.p.add(operator.adjoint(self.r.get_item(0)), out=self.p)\n",
    "        self.s = self.p.copy()\n",
    "        self.s1 = gradient.domain_geometry().allocate(None)\n",
    "\n",
    "        self.norms = self.p.norm()\n",
    "        self.norms0 = self.norms\n",
    "        self.gamma = self.norms**2\n",
    "        self.normx = self.x.norm()\n",
    "        \n",
    "        \n",
    "        self.loss.append(self.r.squared_norm())\n",
    "        self.configured = True\n",
    "        print(\"{} configured\".format(self.__class__.__name__, ))\n",
    "     \n",
    "    def update(self):\n",
    "        '''single iteration'''\n",
    "        operator = self.operator.get_item(0,0)\n",
    "        gradient = self.operator.get_item(0,1)\n",
    "        operator.direct(self.p, out=self.q.get_item(0))\n",
    "        delta0 = self.q.get_item(0).squared_norm()\n",
    "        # self.operator.get_item(0,0).direct(self.p, out=self.q.get_item(0))\n",
    "        # delta0 = self.q.get_item(0).squared_norm()\n",
    "        delta1, a = gradient.direct_L21norm(self.p, out=self.q.get_item(1))\n",
    "        #term1.multiply(gradient.scalar, out=self.q.get_item(1))\n",
    "        self.q.get_item(1).multiply(gradient.scalar, out=self.q.get_item(1))\n",
    "        \n",
    "        delta = delta0 + delta1 * numpy.abs(gradient.scalar)\n",
    "        # print (\"delta\", delta, \"delta0\", delta0, \"delta1\", delta1)\n",
    "        # delta = self.q.squared_norm()\n",
    "\n",
    "        alpha = self.gamma/delta\n",
    "        t0 = time.time()\n",
    "        self.r.axpby(1, -alpha, self.q, out=self.r)\n",
    "        \n",
    "        # print (\"alpha\", alpha)                        \n",
    "        # self.x += alpha * self.p\n",
    "        # self.r -= alpha * self.q\n",
    "        \n",
    "        self.x.axpby(1, alpha, self.p, out=self.x)\n",
    "        #self.x += alpha * self.p\n",
    "        #self.r -= alpha * self.q\n",
    "\n",
    "        # adjoint of block operator is sum of adjoints\n",
    "        # sumsq, self.s = self.operator.adjoint(self.r)\n",
    "        \n",
    "        operator.adjoint(self.r.get_item(0), out=self.s)\n",
    "        delta0 = self.s.norm()\n",
    "\n",
    "        delta1, a = gradient.adjoint_L21norm(self.r.get_item(1), out=self.s1)\n",
    "        self.norms = delta0 + numpy.sqrt(delta1) * gradient.scalar\n",
    "        # self.norms = self.s.norm()\n",
    "\n",
    "        #term0.add(term1, out=self.s)\n",
    "        self.s.axpby(1,gradient.scalar, self.s1, out=self.s)\n",
    "        \n",
    "        # print (\"self.norms {}\".format(self.norms))\n",
    "        \n",
    "        self.gamma1 = self.gamma\n",
    "        self.gamma = self.norms**2\n",
    "        self.beta = self.gamma/self.gamma1\n",
    "        self.p.axpby(self.beta, 1., self.s , out=self.p)\n",
    "        \n",
    "        self.normx = self.x.norm()\n",
    "        # self.xmax = numpy.maximum(self.xmax, self.normx)\n",
    "\n",
    "\n",
    "\n",
    "from ccpi.optimisation.algorithms import RCGLS\n",
    "rcgls = LRCGLS(operator=A, data = tomost, \n",
    "              update_objective_interval = 10, \n",
    "             max_iteration=100, alpha=alpha, \n",
    "             preallocate=True)\n",
    "\n",
    "\n",
    "# rcgls.operator.get_item(0,1).adjoint_L21norm = rcgls.operator.get_item(0,1).operator.adjoint_L21norm\n",
    "rcgls.run(50, callback=save_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = (cgls_regularised.get_output()/rcgls.get_output())\n",
    "print (a.min(), a.max())\n",
    "print (cgls_regularised.get_output().min(), cgls_regularised.get_output().max())\n",
    "print (rcgls.get_output().min(), rcgls.get_output().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type (cgls_regularised.get_output()), type(rcgls.get_output()))\n",
    "from ccpi.utilities.jupyter import link_islicer\n",
    "sl1 = islicer(rcgls.get_output(), direction='horizontal_y')\n",
    "sl2 = islicer(cgls_regularised.get_output(), direction='horizontal_y')\n",
    "sl3 = islicer((cgls_regularised.get_output()/rcgls.get_output()), direction='horizontal_y', minmax=(0.9988101, 0.9988458))\n",
    "link_islicer(sl1,sl2, sl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter2D(cgls_regularised.get_output().subset(horizontal_y=2000), stretch_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "islicer(cgls_regularised.get_output(), \n",
    "        direction='horizontal_y', \n",
    "        slice_number = 50,\n",
    "        cmap='viridis', \n",
    "        size=12, \n",
    "        minmax=(2.e-4, 3.e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=64, continuous_update=False, description='horizontal_y', max=99), FloatRâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f45ef6fbbe894402888fa2ad3575ac6e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "IntSlider(value=64, continuous_update=False, description='horizontal_y', max=99)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db674e42763646a2a0439c173995490c"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# cgls_regularised.run(20)\n",
    "islicer(rcgls.get_output(), \n",
    "        direction='horizontal_y', \n",
    "        slice_number = 64 ,\n",
    "        cmap='viridis', \n",
    "        size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "islicer(cgls_regularised.get_output(),  direction='horizontal_x', cmap='viridis', size=12, minmax=(0.4e-5,6.5e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccpi\n",
    "\n",
    "\n",
    "from ccpi.io import NEXUSDataWriter\n",
    "writer = NEXUSDataWriter()\n",
    "writer.set_up(data_container=cgls_regularised.get_output(), file_name=\"./protein.nxs\")\n",
    "writer.write_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccpi.optimisation.operators import BlockOperator\n",
    "from ccpi.optimisation.functions import BlockFunction, IndicatorBox\n",
    "\n",
    "# Define Gradient Operator and BlockOperator \n",
    "Grad = Gradient(ig)\n",
    "K = BlockOperator(Grad,A)\n",
    "\n",
    "# Define BlockFunction F using the MixedL21Norm() and the L2NormSquared()\n",
    "alpha = 20.\n",
    "f1 = alpha * MixedL21Norm()\n",
    "f2 = L2NormSquared(b=tomost)\n",
    "F = BlockFunction(f1,f2)\n",
    "\n",
    "# Define BlockFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G, as a positivity constraint\n",
    "G = IndicatorBox(lower=0)\n",
    "\n",
    "# Compute operator norm and choose step-size sigma and tau such that sigma*tau||K||^{2}<1\n",
    "normK =  K.norm()\n",
    "sigma = 1\n",
    "tau = 1/(sigma*normK**2)\n",
    "\n",
    "pdhg = PDHG(f = F, g = G, operator = K, tau = tau, sigma = sigma, \n",
    "            max_iteration = 1000, update_objective_interval = 1)\n",
    "\n",
    "pdhg.update_objective_interval = 10\n",
    "pdhg.run(90, very_verbose=True)\n",
    "\n",
    "algo = PDHG(max_iteration=100, operator=A, f=L2NormSquared(b=tomost), g=ZeroFunction(), \n",
    "            tau=tau, sigma=sigma)\n",
    "algo.run(5, very_verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "islicer(pdhg.get_output(), direction='vertical', cmap='viridis', size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mrcfile.open('tomo_01.ali') as mrc:\n",
    "    #ndarray = mrc.data.copy()\n",
    "    shape = mrc.data.shape\n",
    "    vox_size = np.asarray(mrc.voxel_size)\n",
    "    print (vox_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccpi.optimisation.functions import LeastSquares\n",
    "f = LeastSquares(A, tomost, c=0.5)\n",
    "print (f(cgls_regularised.get_output()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (cgls_regularised.r.squared_norm()/tomost.size)\n",
    "print (tomost.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from ccpi.framework import AcquisitionData, AcquisitionGeometry, ImageData, ImageGeometry\n",
    "import datetime\n",
    "from PIL import Image\n",
    "\n",
    "class TIFFWriter(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 **kwargs):\n",
    "        \n",
    "        self.data_container = kwargs.get('data_container', None)\n",
    "        self.file_name = kwargs.get('file_name', None)\n",
    "        \n",
    "        if ((self.data_container is not None) and (self.file_name is not None)):\n",
    "            self.set_up(data_container = self.data_container,\n",
    "                        file_name = self.file_name)\n",
    "        \n",
    "    def set_up(self,\n",
    "               data_container = None,\n",
    "               file_name = None):\n",
    "        \n",
    "        self.data_container = data_container\n",
    "        self.file_name = file_name\n",
    "        \n",
    "        if not ((isinstance(self.data_container, ImageData)) or \n",
    "                (isinstance(self.data_container, AcquisitionData))):\n",
    "            raise Exception('Writer supports only following data types:\\n' +\n",
    "                            ' - ImageData\\n - AcquisitionData')\n",
    "\n",
    "    def write_file(self):\n",
    "        '''alias of write'''\n",
    "        return self.write()\n",
    "    \n",
    "    def write(self):\n",
    "        ndim = len(self.data_container.shape)\n",
    "        if ndim == 2:\n",
    "            # save single slice\n",
    "            with open(self.file_name, 'wb') as f:\n",
    "                Image.fromarray(self.data_container.as_array()).save(f, 'tiff')\n",
    "        elif ndim == 3:\n",
    "            for sliceno in range(self.data_container.shape[0]):\n",
    "                # save single slice\n",
    "                # pattern = self.file_name.split('.')\n",
    "                dimension = self.data_container.dimension_labels[0]\n",
    "                fname = \"{}_idx_{}.tiff\".format(self.file_name.strip(\".tiff\"), sliceno)\n",
    "                with open(fname, 'wb') as f:\n",
    "                    Image.fromarray(self.data_container.as_array()[sliceno]).save(f, 'tiff')\n",
    "        elif ndim == 4:\n",
    "            for sliceno1 in range(self.data_container.shape[0]):\n",
    "                # save single slice\n",
    "                # pattern = self.file_name.split('.')\n",
    "                dimension = [ self.data_container.dimension_labels[0] ]\n",
    "                for sliceno2 in range(self.data_container.shape[1]):\n",
    "                    idx = self.data_container.shape[0] * sliceno2 + sliceno1 \n",
    "                    fname = \"{}_{}_{}_idx_{}.tiff\".format(self.file_name.strip(\".tiff\"), \n",
    "                        self.data_container.shape[0], self.data_container.shape[1], idx)\n",
    "                    with open(fname, 'wb') as f:\n",
    "                        Image.fromarray(self.data_container.as_array()[sliceno1][sliceno2]).save(f, 'tiff')\n",
    "        else:\n",
    "            raise ValueError('Cannot handle more than 4 dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cgls_regularised.get_output().shape)\n",
    "\n",
    "writer = TIFFWriter()\n",
    "writer.set_up(data_container=cgls_regularised.get_output(), file_name=\"cgls_regularised\")\n",
    "writer.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linspace(0,np.pi, 10))\n",
    "# AcquisitionGeometry??\n",
    "ag = AcquisitionGeometry(geom_type='cone', pixel_num_h=10, pixel_num_v=11, channels=2, angles = np.linspace(0,np.pi, 9))\n",
    "ad = ag.allocate(value='random')\n",
    "\n",
    "print (ad.dtype, ad.shape)\n",
    "import re\n",
    "# re.match??\n",
    "match = re.search('.tiff', \"test4d.tiff\")\n",
    "print (match)\n",
    "print (\"match\", re.search('.tiff', \"test4d.tiff\"))\n",
    "writer = TIFFWriter()\n",
    "writer.set_up(data_container=ad, file_name=\"test4d.tiff\")\n",
    "writer.write()\n",
    "# !rm *.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n",
    "dslice = np.array(Image.open('cgls_regularised_idx_1.tiff'))\n",
    "plotter2D(dslice, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n",
    "for i in range(10):\n",
    "    print (\"a_{:04d}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = ImageGeometry(1,2,3)\n",
    "a = ig.allocate(1)\n",
    "b = ig.allocate(2)\n",
    "c = ig.allocate(3)\n",
    "bdc0 = BlockDataContainer(a,b)\n",
    "\n",
    "bdc1 = BlockDataContainer(c,0)\n",
    "\n",
    "bdc0 - bdc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}